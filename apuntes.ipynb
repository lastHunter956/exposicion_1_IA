{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "210064d811a5ed49",
   "metadata": {},
   "source": [
    "# DeBERTa (Decoding-enhanced BERT with disentangled attention) is a Transformer-based\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3276be163fd7642c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T23:57:38.807054400Z",
     "start_time": "2023-10-09T23:57:38.769960400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a420d659838cd14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T23:57:38.880973400Z",
     "start_time": "2023-10-09T23:57:38.799040100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              ID                                       Tweet Dimension  \\\n0  2018-Es-00766                     Dios que susto lpmmm üôèüò°   valence   \n1  2018-Es-01333     Que lindo que es viajar en moto vieja     valence   \n2  2018-Es-06190                   que ansiedad de mierda vo   valence   \n3  2018-Es-05144  La ansiedad no desaprovecha ni un segundo.   valence   \n4  2018-Es-04187                       @ts8rr8t Mucho gusto.   valence   \n\n   Intensity                                        Description  \n0         -2  se infiere un estado emocional moderadamente n...  \n1          2  se infiere un estado emocional moderadamente p...  \n2         -3        se infiere un estado emocional muy negativo  \n3         -2  se infiere un estado emocional moderadamente n...  \n4          2  se infiere un estado emocional moderadamente p...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Tweet</th>\n      <th>Dimension</th>\n      <th>Intensity</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-Es-00766</td>\n      <td>Dios que susto lpmmm üôèüò°</td>\n      <td>valence</td>\n      <td>-2</td>\n      <td>se infiere un estado emocional moderadamente n...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-Es-01333</td>\n      <td>Que lindo que es viajar en moto vieja</td>\n      <td>valence</td>\n      <td>2</td>\n      <td>se infiere un estado emocional moderadamente p...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-Es-06190</td>\n      <td>que ansiedad de mierda vo</td>\n      <td>valence</td>\n      <td>-3</td>\n      <td>se infiere un estado emocional muy negativo</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-Es-05144</td>\n      <td>La ansiedad no desaprovecha ni un segundo.</td>\n      <td>valence</td>\n      <td>-2</td>\n      <td>se infiere un estado emocional moderadamente n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-Es-04187</td>\n      <td>@ts8rr8t Mucho gusto.</td>\n      <td>valence</td>\n      <td>2</td>\n      <td>se infiere un estado emocional moderadamente p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conociendo la base de datos\n",
    "datos_test = pd.read_csv('Valence_test_oc_es.csv', sep=';')\n",
    "datos_train = pd.read_csv('Valence_train_oc_es.csv', sep=';')\n",
    "datos_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd4e806ccb0ccc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T23:57:52.354624700Z",
     "start_time": "2023-10-09T23:57:47.784493200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importar las librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DebertaTokenizer, DebertaForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef7a636c443e3243",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T23:58:04.690272200Z",
     "start_time": "2023-10-09T23:58:04.643571300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Leer los datos de train y test desde los archivos csv\n",
    "train_data = pd.read_csv(\"Valence_train_oc_es.csv\", sep=';')\n",
    "test_data = pd.read_csv(\"Valence_test_oc_es.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c74b07c52f0fcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T23:58:09.139332400Z",
     "start_time": "2023-10-09T23:58:06.387265300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'pooler.dense.weight', 'classifier.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Crear el tokenizador y el modelo de DeBERTa\n",
    "tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "model = DebertaForSequenceClassification.from_pretrained(\"microsoft/deberta-base\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16b67ac13f7b1d3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T23:58:11.031236400Z",
     "start_time": "2023-10-09T23:58:10.317659500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convertir los tweets y las etiquetas a tensores\n",
    "train_tweets = tokenizer(train_data[\"Tweet\"].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "train_labels = torch.tensor(train_data[\"Intensity\"].tolist())\n",
    "test_tweets = tokenizer(test_data[\"Tweet\"].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_labels = torch.tensor(test_data[\"Intensity\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a56192849e16384d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T23:58:13.870110100Z",
     "start_time": "2023-10-09T23:58:13.069659500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definir el optimizador y la funci√≥n de p√©rdida\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d54abf5ecb51713",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-09T23:58:14.611444100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Entrenar el modelo con los datos de train\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "  outputs = model(**train_tweets, labels=train_labels)\n",
    "  loss = outputs.loss\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "  print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57b08836543d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo con los datos de test\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  outputs = model(**test_tweets)\n",
    "  predictions = torch.argmax(outputs.logits, dim=1)\n",
    "  accuracy = accuracy_score(test_labels, predictions)\n",
    "  print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96068a8f33327e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
